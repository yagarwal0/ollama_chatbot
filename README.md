With this code, we can use the locally deployed Ollama Model Lamma3.2 to chat

Step to use it.
* Firstly download the ollama from it's official website
* In the CMD type the command ollama pull llama3.2 to download the llama 3.2
* Open VS Code
